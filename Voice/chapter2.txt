How Do We and the Computer See?
The Human Visual System

In order to understand how to deal with images, we have to understand what seeing is and how it works.

Humans see when the reflection of light bounces off of an object and falls on the retina(the bundle of nerve sensors in the eye). A lens controls the focus and sharpness of the image. Rods in the retina detect illumination levels while Cones detect colors(there are around 10x more rods than cones). The Distance between the lens and the retina is constant. To focus, the lens changes shape by either being squished or flattened, changing the focal length and thus the sharpness. When light falls onto the retina, electrical impulses are created and are sent to the brain via the optic nerve. The Image is upside down, since there is only 1 lens.

Diagram of the Human Eye
The Computer

    Images can be produced using different regions of the Electromagnetic Spectrum(x-rays,microwave,MRI, photography,etc)

Displaying Images

    Images are displayed as a discrete set of intensities.

    The Eye's ability to discriminate between different intensity levels is an important consideration in presenting image processing results. The Main goal of image processing is to improve images. The Final judge is the human. Therefore it is very important to consider the human eye when

    The Human visual system can perceive around 10^10 different light intensity levels.

    However, at any one time we can discriminate between a much smaller number of intensities ie the current sensitivity of the visual system.

    Perceived intensity of a region is related to the light intensities of the regions around it. Perceived brightness is not a simple function of intensity. The Visual system tends to overshoot or undershoot around the boundary of regions of different intensities.
        One phenomena to demonstrate this is the mach band,where we see "concaveness" around the boundaries between the stripes even though they are of constant brightness

    mach band
        Another Phenomena is simultaneous contrast, where a color seems lighter or darker depending on the surrounding region

    simeltaneeous contrast
        Yet Another Phenomena is optical illusions, where objects seem larger, smaller, moving, or cause us to perceive things that aren't there because of how the visual system works(and fills in stuff that isnt there sometimes). An example is this trippy picture.

    trippy picture

Light and the Electromagnetic spectrum

    Light is a (very small) part of the Electromagnetic Spectrum that can be sensed by the human eye(400nm to 700nm).

    The Electromagnetic Spectrum is split up according to wavelengths of different forms of energy.

    This was discovered in 1666 by Issac Newton when he noticed that light split into a spectrum after passing through a piece of glass.

    Humans perceive color based on the light reflected from an object. A green object for example, absorbs everything except green, so we see it as green.

    Light That has no color is called monochromatic or achromatic.

        Its only attribute is intensity.

        Because monochromatic light is perceived from black to white with a set of grays between , we refer to it using gray level.
            Intensity level and gray level mean the same thing.

    Light that has color is called chromatic.

        Its attributes in addition to the frequency of the light wave(which gives us the color) are :

            Radiance : The Energy reflected from the object.

            Luminance : The Energy perceived by the observer.

            Brightness : A Subjective property that is hard to measure but gives the notion of intensity.

Image Acquisition

    Image Acquisition is a problem domain

    Most of the images we are interested in are generated by the combination of an "illumination" source and a reflection or absorption of the energy from a source by the clements of the "scene" being imaged ie, to create an image, we need :

        A Source of illumination.

        Devices to collect the energy reflected from or transmitted through the objects.

    Radiance is the total energy that flows from the light source.

    Luminance is the level of energy perceived from the light source.

    The Fundamental Limit of Image Acquisition :

    To See an Object, The Electromagnetic Wavelength Must Be No Bigger Than the Object.

Sensing

there are three arrangements of sensors :

    Single Imaging Sensors : Just a singular sensor on its own. an Example of its usage is for IR data transmission.

    Line Imagining Sensors : A Group of sensors in a Line. An example of their usage is in Flatbed Scanners and Bar code readers.

    Array Sensors : A Group Sensors in an array Used in DSLR or Phone Cameras(Square) or MRI(Round).

In all cases, incoming light lands on a sensor material responsive to that type of energy, generating a voltage. for details on how images are generated from a physical property, see the image formation model. it can be summarized by

    f(x,y)=i(x,y)+r(x,y)

where i is the illumination, the amount of light that falls on scene, and r is the reflectance, the amount of light reflected off the object in the scene.

    Sensors used in acquisition produce a continuous voltage signal. A Digital sensor can only measure a limited number of samples at a discrete set of energy levels.

    A Digital form of an image is produced through two processes :

        Sampling(Digitization) : digitizing the intensity of spatial coordinates x,y.

        Quantization(Discretization) : converting the intensity of x,y into discrete levels.

